# -*- coding: utf-8 -*-
"""AnomalyDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xl6cW68JWmTU7xVYyr_vseBvD3BMCYJG
"""

!pip install torch torchvision pandas numpy matplotlib scikit-learn kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d mlg-ulb/creditcardfraud
!unzip creditcardfraud.zip

import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset, random_split
from sklearn.preprocessing import StandardScaler

"""# Loading and Preprocessing the Dataset"""

data = pd.read_csv('creditcard.csv')
scaler = StandardScaler()
data['Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))

data = data.drop(['Time'], axis=1)

X = data.drop(['Class'], axis=1).values
y = data['Class'].values

X_normal = X[y == 0]

X_normal = torch.tensor(X_normal, dtype=torch.float32)

"""# Creating an Autoencoder Model"""

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder, self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(29, 14),
        nn.ReLU(),
        nn.Linear(14, 7),
        nn.ReLU(),
        nn.Linear(7,3)
    )
    self.decoder = nn.Sequential(
        nn.Linear(3, 7),
        nn.ReLU(),
        nn.Linear(7, 14),
        nn.ReLU(),
        nn.Linear(14, 29),
        nn.Sigmoid()
    )

  def forward(self,x):
    x = self.encoder(x)
    x = self.decoder(x)
    return x

"""# Initializing Model, Loss Function and Optimizer"""

model = Autoencoder()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

"""# Training the Autoencoder"""

dataset = TensorDataset(X_normal)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

num_epochs = 20

for epoch in range(num_epochs):
  for data in dataloader:
    inputs = data[0]
    outputs = model(inputs)
    loss = criterion(outputs, inputs)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

"""# Detect Anomaly"""

X_all = torch.tensor(X, dtype=torch.float32)

with torch.no_grad():
  reconstructions = model(X_all)
  reconstruction_errors = torch.mean((X_all - reconstructions)** 2, dim=1).numpy()

threshold = np.percentile(reconstruction_errors, 95)

anomalies = reconstruction_errors > threshold
print(f'Number of detected anomalies: {np.sum(anomalies)}')

actual_frauds = y == 1
print(f'Number of actual frauds: {np.sum(actual_frauds)}')

true_positives = np.sum(anomalies & actual_frauds)
false_positives = np.sum(anomalies & ~actual_frauds)
true_negatives = np.sum(~anomalies & ~actual_frauds)
false_negatives = np.sum(~anomalies & actual_frauds)

print(f'True Positives: {true_positives}')
print(f'False Positives: {false_positives}')
print(f'True Negatives: {true_negatives}')
print(f'False Negatives: {false_negatives}')

"""# Visualization"""

plt.hist(reconstruction_errors, bins=50)
plt.xlabel('Reconstruction error')
plt.ylabel('Number of transactions')
plt.title('Distribution of Reconstruction Errors')
plt.show()